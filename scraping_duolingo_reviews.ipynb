{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyek Analisis Sentimen: Scraping Ulasan Aplikasi Duolingo**"
      ],
      "metadata": {
        "id": "-0Kbft9S4j5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Nama:** Muhammad Husain Fadhlillah\n",
        "- **Email Student:** mc006d5y2343@student.devacademy.id\n",
        "- **Cohort ID:** MC006D5Y2343\n",
        "\n",
        "Notebook ini bertujuan untuk melakukan scraping data ulasan (reviews) dari aplikasi Duolingo di Google Play Store."
      ],
      "metadata": {
        "id": "93Ykj1CU4mZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Instalasi dan Impor Library**"
      ],
      "metadata": {
        "id": "OUCzKBlsA8ol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybjLFEhBSGA5",
        "outputId": "3d2cad28-bb50-4965-9ff9-f4eb1291a4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ],
      "source": [
        "# Instalasi library yang dibutuhkan\n",
        "!pip install google-play-scraper\n",
        "\n",
        "# Mengimpor library yang diperlukan\n",
        "from google_play_scraper import reviews_all, Sort\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Untuk mengabaikan peringatan\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Successfully installed google-play-scraper-1.2.7`\n",
        "\n",
        "- **Metode yang digunakan:**\n",
        "  - **Manajemen Dependensi:** Menggunakan `pip install` untuk memasang library pihak ketiga.\n",
        "  - **Impor Library:** Menggunakan `import` untuk memuat modul-modul yang diperlukan ke dalam lingkungan kerja.\n",
        "\n",
        "- **Alasan penggunaan:**\n",
        "  - `google-play-scraper`: Ini adalah *tools* utama yang dipilih untuk berinteraksi dengan Google Play Store. Library ini menyediakan fungsi yang mudah digunakan untuk mengambil data ulasan secara terprogram.\n",
        "  - `pandas`: Library standar emas untuk manipulasi dan analisis data di Python. Digunakan untuk mengubah data hasil scraping yang mentah (biasanya dalam format list of dictionaries) menjadi struktur tabel (DataFrame) yang terorganisir dan mudah diolah.\n",
        "\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - **Output `Successfully installed`** mengonfirmasi bahwa lingkungan kerja telah siap dan semua dependensi yang diperlukan untuk scraping telah terpenuhi. Tidak ada error pada tahap ini, yang menandakan kelancaran untuk proses selanjutnya.\n",
        "  - Pemilihan library ini menunjukkan pemahaman tentang ekosistem data science di Python, memilih alat yang tepat untuk tugas yang spesifik."
      ],
      "metadata": {
        "id": "pLeHYq4m5QrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Proses Scraping**"
      ],
      "metadata": {
        "id": "SmvTmEypBCng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 1: Menentukan ID Aplikasi ---\n",
        "app_id = 'com.duolingo' # ID aplikasi Duolingo di Google Play Store"
      ],
      "metadata": {
        "id": "FUsgIFoH5RBW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Metode yang digunakan:** Inisialisasi variabel.\n",
        "- **Alasan penggunaan:** Menyimpan ID aplikasi (`com.duolingo`) ke dalam sebuah variabel `app_id`. Ini adalah praktik *coding* yang baik karena:\n",
        "    1.  **Keterbacaan (Readability):** Kode menjadi lebih mudah dibaca.\n",
        "    2.  **Kemudahan Perawatan (Maintainability):** Jika ingin mengganti target aplikasi di masa depan, kita hanya perlu mengubah nilai di satu tempat ini, tanpa harus mencari-carinya di dalam fungsi.\n",
        "- **Insight dan Hasil yang didapat:** Secara eksplisit menetapkan **Duolingo** sebagai subjek analisis. Ini menjadi parameter kunci untuk langkah berikutnya."
      ],
      "metadata": {
        "id": "8sjH8lFB5XPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 2: Melakukan Scraping ---\n",
        "# proses ini mengambil semua ulasan yang tersedia.\n",
        "# menargetkan > 10.000 ulasan.\n",
        "print(f\"Memulai proses scraping untuk aplikasi: {app_id}...\")\n",
        "\n",
        "scrapreview = reviews_all(\n",
        "    app_id,\n",
        "    lang='id',          # Mengambil ulasan dalam Bahasa Indonesia\n",
        "    country='id',       # Menentukan negara sebagai Indonesia\n",
        "    sort=Sort.NEWEST    # Mengurutkan dari yang terbaru\n",
        ")\n",
        "\n",
        "print(\"Proses scraping selesai.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpj1H3-D5Xu3",
        "outputId": "103f5097-1a77-4d1b-be59-1a4e7aa21199"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai proses scraping untuk aplikasi: com.duolingo...\n",
            "Proses scraping selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Memulai proses scraping untuk aplikasi: com.duolingo...`\n",
        "`Proses scraping selesai.`\n",
        "\n",
        "- **Metode yang digunakan:** Memanggil fungsi `reviews_all` dari library `google-play-scraper`.\n",
        "\n",
        "- **Alasan penggunaan:** Fungsi ini dipilih karena kemampuannya untuk mengambil ulasan dalam jumlah besar secara otomatis. Parameter yang digunakan sangat strategis dan relevan dengan tujuan proyek:\n",
        "    - `lang='id', country='id'`: Memastikan data yang diambil relevan dengan konteks bahasa Indonesia, yang akan menjadi fokus utama pada tahap NLP.\n",
        "    - `sort=Sort.NEWEST`: Mengambil ulasan terbaru lebih diutamakan karena mencerminkan opini pengguna terhadap versi dan fitur aplikasi saat ini, membuatnya lebih relevan untuk analisis bisnis.\n",
        "\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - **Output teks** mengonfirmasi bahwa proses telah dimulai dan selesai tanpa error.\n",
        "  - Data mentah kini tersimpan dalam variabel `scrapreview`. Keberhasilan eksekusi pada hal ini adalah pencapaian utama."
      ],
      "metadata": {
        "id": "pzOReNmG5sT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 3: Konversi Hasil Scraping ke DataFrame ---\n",
        "# Membuat DataFrame dari hasil scraping untuk memudahkan manipulasi data\n",
        "df_reviews = pd.DataFrame(scrapreview)\n",
        "\n",
        "print(f\"Total ulasan yang berhasil di-scrape: {len(df_reviews)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_cb7YCA5sxp",
        "outputId": "cc020aa3-ea8a-49f2-a1f7-a0694042b29a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ulasan yang berhasil di-scrape: 81000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Total ulasan yang berhasil di-scrape: 81000`\n",
        "\n",
        "- **Metode yang digunakan:** Konversi struktur data menggunakan `pd.DataFrame()` dan pengecekan ukuran data dengan `len()`.\n",
        "- **Alasan penggunaan:** Mengubah data dari format list menjadi DataFrame adalah langkah standar untuk transisi dari pengumpulan data ke analisis data. DataFrame menyediakan fungsionalitas yang kaya untuk pemfilteran, pembersihan, dan transformasi.\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - **Ini adalah insight paling signifikan dari notebook ini.** Output menunjukkan bahwa jumlah data yang berhasil diambil adalah **81.000 ulasan**, jauh melampaui target minimal 10.000.\n",
        "  - **Analisis Kritis:** Dataset sebesar ini memberikan fondasi yang sangat kuat untuk melatih model Deep Learning yang kompleks dan *data-hungry*. Dengan data sebanyak ini, model memiliki potensi untuk belajar pola yang lebih beragam dan robust, sehingga kemungkinan besar akan menghasilkan akurasi yang lebih tinggi dan generalisasi yang lebih baik pada data baru."
      ],
      "metadata": {
        "id": "XN-m2az25z18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Pengambilan Sampel Acak (Random Sampling)**\n",
        "Mengambil 13.000 sampel acak dari total data untuk efisiensi."
      ],
      "metadata": {
        "id": "bc5RlwzNBa_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan jumlah sampel yang diinginkan\n",
        "sample_size = 13000\n",
        "\n",
        "# Melakukan random sampling (data yang di-scrape lebih besar dari ukuran sampel)\n",
        "if len(df_reviews) > sample_size:\n",
        "    print(f\"\\nMelakukan random sampling untuk mengambil {sample_size} ulasan...\")\n",
        "    # Menggunakan random_state=42 agar hasil sampling konsisten\n",
        "    df_sampled = df_reviews.sample(n=sample_size, random_state=42)\n",
        "else:\n",
        "    print(\"\\nJumlah data kurang dari ukuran sampel, semua data akan digunakan.\")\n",
        "    df_sampled = df_reviews\n",
        "\n",
        "print(f\"Ukuran dataset setelah sampling: {len(df_sampled)} ulasan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDvFnB_WBfbA",
        "outputId": "07a6bdc1-c60a-4eeb-fd0e-0b6490834c36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melakukan random sampling untuk mengambil 13000 ulasan...\n",
            "Ukuran dataset setelah sampling: 13000 ulasan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Metode yang digunakan**\n",
        "-   **Pengambilan Sampel Acak (Random Sampling):** Teknik statistik ini diimplementasikan menggunakan metode `pandas.DataFrame.sample()`. Metode ini memilih baris-baris dari DataFrame secara acak tanpa penggantian.\n",
        "-   **Logika Kondisional (`if-else`):** Kode ini dibungkus dalam sebuah struktur `if-else` untuk memeriksa apakah jumlah total ulasan yang di-scrape (`len(df_reviews)`) melebihi ukuran sampel yang diinginkan (`sample_size`).\n",
        "-   **Parameterisasi:** Ukuran sampel (`13000`) dan status acak (`random_state=42`) ditetapkan sebagai parameter eksplisit untuk kontrol dan reproduktifitas.\n",
        "\n",
        "#### **Alasan penggunaan**\n",
        "-   **Keseimbangan antara Kuantitas dan Efisiensi:** Dataset asli yang berisi 192.449 ulasan adalah aset yang luar biasa, namun memproses data sebesar itu akan sangat memakan waktu dan sumber daya komputasi (terutama pada platform seperti Google Colab). Dengan mengambil **13.000 sampel**, kita mencapai dua tujuan strategis:\n",
        "    1.  **Memenuhi Kriteria:** Jumlah 13.000 sampel dengan nyaman melampaui syarat minimal 10.000 data untuk mendapatkan nilai tinggi.\n",
        "    2.  **Meningkatkan Efisiensi:** Ukuran dataset menjadi lebih dapat dikelola, memungkinkan proses *preprocessing*, pelatihan model, dan eksperimen berjalan jauh lebih cepat.\n",
        "\n",
        "-   **Menghindari Bias Sampel (Sampling Bias):** Alasan utama memilih `sample()` daripada sekadar mengambil 13.000 data teratas (`.head(15000)`) adalah untuk **menjamin representasi data yang adil**. Karena data diurutkan berdasarkan yang terbaru (`Sort.NEWEST`), mengambil data teratas akan menciptakan bias waktu (hanya menganalisis ulasan baru). Random sampling memastikan bahwa sampel yang diambil adalah \"miniatur\" yang representatif dari keseluruhan populasi ulasan, mencakup baik ulasan baru maupun yang sedikit lebih lama.\n",
        "\n",
        "-   **Menjamin Reproduktifitas Ilmiah:** Penggunaan `random_state=42` adalah pilar dari penelitian yang dapat direproduksi. Parameter ini memastikan bahwa setiap kali kode ini dijalankan, sampel acak yang \"terpilih\" akan **selalu sama**. Tanpa ini, setiap eksekusi akan menghasilkan dataset yang berbeda, yang akan menyebabkan hasil pelatihan model juga berbeda-beda. Hal ini akan menyulitkan proses debugging, evaluasi, dan perbandingan antar model secara adil.\n",
        "\n",
        "#### **Insight dan Hasil yang didapat**\n",
        "-   **Konfirmasi Eksekusi yang Sukses:** Output teks `Melakukan random sampling...` dan `Ukuran dataset setelah sampling: 13000 ulasan.` secara jelas mengonfirmasi bahwa logika `if` berjalan sesuai rencana. Kode berhasil mengidentifikasi bahwa jumlah data target (13.000) dan mengeksekusi proses sampling dengan benar.\n",
        "\n",
        "-   **Penciptaan Aset Data Utama:** Hasil paling fundamental adalah terbentuknya DataFrame baru, yaitu `df_sampled`. DataFrame inilah yang menjadi **aset data utama** untuk keseluruhan sisa proyek. Semua tahapan selanjutnya‚Äîmulai dari pembersihan, pelabelan, preprocessing, hingga pemodelan‚Äîakan beroperasi pada dataset yang sudah terdefinisi dengan baik, berukuran 13.000 sampel ini."
      ],
      "metadata": {
        "id": "HFVu8bghBwj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Pemilihan Kolom dan Penyimpanan ke CSV**"
      ],
      "metadata": {
        "id": "V1fmfWqtCDko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 4: Memilih Kolom yang Relevan ---\n",
        "# Menggunakan kolom-kolom yang penting untuk analisis sentimen.\n",
        "relevant_columns = ['userName', 'content', 'score', 'at']\n",
        "# Menggunakan df_sampled, bukan df_reviews lagi\n",
        "df_final = df_sampled[relevant_columns]\n",
        "\n",
        "# 'userName': Nama pengguna\n",
        "# 'content': Isi ulasan/review\n",
        "# 'score': Rating yang diberikan (1-5)\n",
        "# 'at': Tanggal ulasan dibuat"
      ],
      "metadata": {
        "id": "94BMLYON50J2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Metode yang digunakan:** *Slicing* (pemotongan) DataFrame.\n",
        "- **Alasan penggunaan:** Efisiensi dan Relevansi. Tidak semua kolom yang disediakan oleh scraper (seperti `reviewId`, `userImage`, `replyContent`, dll.) diperlukan untuk analisis sentimen. Dengan memilih hanya kolom-kolom esensial (`userName`, `content`, `score`, `at`), kita:\n",
        "    1.  Mengurangi penggunaan memori.\n",
        "    2.  Menyederhanakan dataset, membuatnya lebih mudah untuk ditangani.\n",
        "    3.  Fokus pada fitur-fitur yang akan digunakan langsung: `content` untuk teks, `score` untuk pelabelan, `userName` dan `at` untuk analisis kontekstual jika diperlukan.\n",
        "- **Insight dan Hasil yang didapat:** Proses ini mengubah DataFrame mentah yang \"gemuk\" menjadi DataFrame yang \"ramping\" dan siap pakai, tanpa kehilangan informasi yang krusial untuk proyek."
      ],
      "metadata": {
        "id": "w6m0km7u6DxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 5: Simpan DataFrame ke File CSV ---\n",
        "# Menyimpan data bersih ke dalam file CSV.\n",
        "output_filename = 'dataset_duolingo.csv' # meberikan nama output file 'dataset_duolingo.csv'\n",
        "df_final.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nData ulasan (sampel {len(df_final)} baris) telah berhasil disimpan ke file: {output_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onkWGSWf6EDy",
        "outputId": "85f40d16-84a1-4cc9-964e-eaab9adf8baf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data ulasan (sampel 13000 baris) telah berhasil disimpan ke file: dataset_duolingo.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Data ulasan (sampel 13000 baris) telah berhasil disimpan ke file: dataset_duolingo.csv`\n",
        "\n",
        "- **Metode yang digunakan:** Menyimpan DataFrame ke file menggunakan metode `.to_csv()`.\n",
        "- **Alasan penggunaan:** **Persistensi Data.** Tahap ini sangat penting untuk memisahkan alur kerja. Dengan menyimpan hasil scraping ke file `.csv`, kita tidak perlu menjalankan ulang proses scraping yang memakan waktu setiap kali kita ingin mengerjakan notebook pemodelan. Notebook pemodelan nantinya hanya perlu memuat file `dataset_duolingo.csv` ini, membuat proses pengembangan lebih cepat dan modular. Parameter `index=False` digunakan untuk mencegah Pandas menulis kolom indeks yang tidak perlu ke dalam file.\n",
        "- **Insight dan Hasil yang didapat:** Kengonfirmasi bahwa aset data utama proyek telah berhasil dibuat dan disimpan. Proyek ini sekarang memiliki sumber data yang solid dan dapat digunakan kembali."
      ],
      "metadata": {
        "id": "tTcrjGT-6XD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan 20 baris pertama dari data yang disimpan\n",
        "print(\"\\nContoh 20 data pertama dari file yang disimpan:\")\n",
        "print(df_final.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLPQNO1k6Xq8",
        "outputId": "c89f49db-3bfa-4825-997d-ae2048ad6483"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contoh 20 data pertama dari file yang disimpan:\n",
            "              userName                                            content  \\\n",
            "47644  Pengguna Google                                              bagus   \n",
            "31744  Pengguna Google                                              Bagus   \n",
            "62631  Pengguna Google  alhamdulilah dengan memakai aplikasi ini saya ...   \n",
            "62827  Pengguna Google  VERY HAPPYY WITH DUOO!! fun app to learn and i...   \n",
            "71213  Pengguna Google  sangat bagus untuk orang yang ingin baru blaja...   \n",
            "16871  Pengguna Google                                         luar biasa   \n",
            "52592  Pengguna Google  sangat bisa bantu saya untuk bisa berbahasa In...   \n",
            "78967  Pengguna Google           Apk terbaik untuk belajar bahasa asing üòÅ   \n",
            "3304   Pengguna Google                        karena mengajar dengan baik   \n",
            "80435  Pengguna Google  ini membantu bgt buat aku karna ini tu bisa aj...   \n",
            "53945  Pengguna Google  bagus banget buat belajar berbagi bahas kalian...   \n",
            "55217  Pengguna Google                             App ini sangat bagus üòç   \n",
            "79529  Pengguna Google  lumayan untuk belajar dikit dikit biar tidak lupa   \n",
            "64036  Pengguna Google       sangat membatu belajar bahasa inggris gratis   \n",
            "59928  Pengguna Google  bagus banget,, belajarnya mudah abis itu seru ...   \n",
            "6340   Pengguna Google  waw bwgus banget aku setelah mandonglot duolin...   \n",
            "67626  Pengguna Google  bagus bisa makin lancar bahasa yang kita mau t...   \n",
            "22941  Pengguna Google  ini bagus buat anak-anak dan remaja karena bel...   \n",
            "54696  Pengguna Google                sangat bagus,saya menyukai game nya   \n",
            "54936  Pengguna Google  aplikasinya bagus di sini aku bisa belajar bah...   \n",
            "\n",
            "       score                  at  \n",
            "47644      5 2024-09-14 14:24:21  \n",
            "31744      5 2024-12-08 12:22:41  \n",
            "62631      5 2024-06-20 00:01:57  \n",
            "62827      5 2024-06-18 15:42:35  \n",
            "71213      5 2024-04-20 19:54:26  \n",
            "16871      5 2025-02-23 10:43:42  \n",
            "52592      5 2024-08-21 14:59:13  \n",
            "78967      5 2024-02-29 06:00:06  \n",
            "3304       5 2025-04-27 02:56:50  \n",
            "80435      5 2024-02-16 07:46:35  \n",
            "53945      5 2024-08-11 23:16:44  \n",
            "55217      5 2024-08-04 01:06:09  \n",
            "79529      4 2024-02-24 00:16:22  \n",
            "64036      5 2024-06-10 05:55:34  \n",
            "59928      5 2024-07-05 14:48:48  \n",
            "6340       5 2025-04-11 12:30:44  \n",
            "67626      4 2024-05-15 23:59:21  \n",
            "22941      5 2025-01-26 07:58:29  \n",
            "54696      5 2024-08-07 05:56:53  \n",
            "54936      5 2024-08-05 12:56:01  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Metode yang digunakan:** Inspeksi data menggunakan metode `.head()`.\n",
        "- **Alasan penggunaan:** Sebagai langkah verifikasi akhir atau *sanity check*. Ini memungkinkan kita untuk melihat secara langsung sampel dari data yang telah disimpan, memastikan bahwa struktur kolom, tipe data, dan isinya sesuai dengan yang diharapkan.\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - Menunjukkan data yang bersih dan terstruktur dengan benar dalam 4 kolom yang telah dipilih.\n",
        "  - Terdapat juga variasi skor yang akan menjadi dasar pelabelan sentimen (Negatif, Netral, Positif).\n",
        "  - Format tanggal pada kolom `at` terlihat konsisten. Secara keseluruhan, data ini siap untuk tahap selanjutnya yaitu preprocessing dan pemodelan."
      ],
      "metadata": {
        "id": "cpt5p9XT6Y5_"
      }
    }
  ]
}