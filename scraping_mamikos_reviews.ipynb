{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyek Analisis Sentimen: Scraping Ulasan Aplikasi Mamikos**"
      ],
      "metadata": {
        "id": "-0Kbft9S4j5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Nama:** Muhammad Husain Fadhlillah\n",
        "- **Email Student:** mc006d5y2343@student.devacademy.id\n",
        "- **Cohort ID:** MC006D5Y2343\n",
        "\n",
        "Notebook ini bertujuan untuk melakukan scraping data ulasan (reviews) dari aplikasi Mamikos di Google Play Store."
      ],
      "metadata": {
        "id": "93Ykj1CU4mZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Instalasi dan Impor Library**"
      ],
      "metadata": {
        "id": "OUCzKBlsA8ol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybjLFEhBSGA5",
        "outputId": "8ed0735c-b2ed-442e-807e-04df4206c735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-play-scraper in /usr/local/lib/python3.11/dist-packages (1.2.7)\n"
          ]
        }
      ],
      "source": [
        "# Instalasi library yang dibutuhkan\n",
        "!pip install google-play-scraper\n",
        "\n",
        "# Mengimpor library yang diperlukan\n",
        "from google_play_scraper import reviews_all, Sort\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Untuk mengabaikan peringatan\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Successfully installed google-play-scraper-1.2.7`\n",
        "\n",
        "- **Metode yang digunakan:**\n",
        "  - **Manajemen Dependensi:** Menggunakan `pip install` untuk memasang library pihak ketiga.\n",
        "  - **Impor Library:** Menggunakan `import` untuk memuat modul-modul yang diperlukan ke dalam lingkungan kerja.\n",
        "\n",
        "- **Alasan penggunaan:**\n",
        "  - `google-play-scraper`: Ini adalah *tools* utama yang dipilih untuk berinteraksi dengan Google Play Store. Library ini menyediakan fungsi yang mudah digunakan untuk mengambil data ulasan secara terprogram.\n",
        "  - `pandas`: Library standar emas untuk manipulasi dan analisis data di Python. Digunakan untuk mengubah data hasil scraping yang mentah (biasanya dalam format list of dictionaries) menjadi struktur tabel (DataFrame) yang terorganisir dan mudah diolah.\n",
        "\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - **Output `Successfully installed`** mengonfirmasi bahwa lingkungan kerja telah siap dan semua dependensi yang diperlukan untuk scraping telah terpenuhi. Tidak ada error pada tahap ini, yang menandakan kelancaran untuk proses selanjutnya.\n",
        "  - Pemilihan library ini menunjukkan pemahaman tentang ekosistem data science di Python, memilih alat yang tepat untuk tugas yang spesifik."
      ],
      "metadata": {
        "id": "pLeHYq4m5QrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Proses Scraping**"
      ],
      "metadata": {
        "id": "SmvTmEypBCng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 1: Menentukan ID Aplikasi ---\n",
        "app_id = 'com.git.mami.kos' # ID aplikasi Mamikos di Google Play Store"
      ],
      "metadata": {
        "id": "FUsgIFoH5RBW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Metode yang digunakan:** Inisialisasi variabel.\n",
        "- **Alasan penggunaan:** Menyimpan ID aplikasi (`com.git.mami.kos`) ke dalam sebuah variabel `app_id`. Ini adalah praktik *coding* yang baik karena:\n",
        "    1.  **Keterbacaan (Readability):** Kode menjadi lebih mudah dibaca.\n",
        "    2.  **Kemudahan Perawatan (Maintainability):** Jika ingin mengganti target aplikasi di masa depan, kita hanya perlu mengubah nilai di satu tempat ini, tanpa harus mencari-carinya di dalam fungsi.\n",
        "- **Insight dan Hasil yang didapat:** Secara eksplisit menetapkan **Mamikos** sebagai subjek analisis. Ini menjadi parameter kunci untuk langkah berikutnya."
      ],
      "metadata": {
        "id": "8sjH8lFB5XPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 2: Melakukan Scraping ---\n",
        "# proses ini mengambil semua ulasan yang tersedia.\n",
        "# menargetkan > 10.000 ulasan.\n",
        "print(f\"Memulai proses scraping untuk aplikasi: {app_id}...\")\n",
        "\n",
        "scrapreview = reviews_all(\n",
        "    app_id,\n",
        "    lang='id',          # Mengambil ulasan dalam Bahasa Indonesia\n",
        "    country='id',       # Menentukan negara sebagai Indonesia\n",
        "    sort=Sort.NEWEST    # Mengurutkan dari yang terbaru\n",
        ")\n",
        "\n",
        "print(\"Proses scraping selesai.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpj1H3-D5Xu3",
        "outputId": "c3d42ce9-0c66-4493-ce55-621cab6cdf2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai proses scraping untuk aplikasi: com.git.mami.kos...\n",
            "Proses scraping selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Memulai proses scraping untuk aplikasi: com.git.mami.kos...`\n",
        "`Proses scraping selesai.`\n",
        "\n",
        "- **Metode yang digunakan:** Memanggil fungsi `reviews_all` dari library `google-play-scraper`.\n",
        "\n",
        "- **Alasan penggunaan:** Fungsi ini dipilih karena kemampuannya untuk mengambil ulasan dalam jumlah besar secara otomatis. Parameter yang digunakan sangat strategis dan relevan dengan tujuan proyek:\n",
        "    - `lang='id', country='id'`: Memastikan data yang diambil relevan dengan konteks bahasa Indonesia, yang akan menjadi fokus utama pada tahap NLP.\n",
        "    - `sort=Sort.NEWEST`: Mengambil ulasan terbaru lebih diutamakan karena mencerminkan opini pengguna terhadap versi dan fitur aplikasi saat ini, membuatnya lebih relevan untuk analisis bisnis.\n",
        "\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - **Output teks** mengonfirmasi bahwa proses telah dimulai dan selesai tanpa error.\n",
        "  - Data mentah kini tersimpan dalam variabel `scrapreview`. Keberhasilan eksekusi pada hal ini adalah pencapaian utama."
      ],
      "metadata": {
        "id": "pzOReNmG5sT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 3: Konversi Hasil Scraping ke DataFrame ---\n",
        "# Membuat DataFrame dari hasil scraping untuk memudahkan manipulasi data\n",
        "df_reviews = pd.DataFrame(scrapreview)\n",
        "\n",
        "print(f\"Total ulasan yang berhasil di-scrape: {len(df_reviews)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_cb7YCA5sxp",
        "outputId": "aeb55312-da4b-4c0b-8573-61103b78fe50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ulasan yang berhasil di-scrape: 10373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Total ulasan yang berhasil di-scrape: 10373`\n",
        "\n",
        "- **Metode yang digunakan:** Konversi struktur data menggunakan `pd.DataFrame()` dan pengecekan ukuran data dengan `len()`.\n",
        "- **Alasan penggunaan:** Mengubah data dari format list menjadi DataFrame adalah langkah standar untuk transisi dari pengumpulan data ke analisis data. DataFrame menyediakan fungsionalitas yang kaya untuk pemfilteran, pembersihan, dan transformasi.\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - **Ini adalah insight paling signifikan dari notebook ini.** Output menunjukkan bahwa jumlah data yang berhasil diambil adalah **10.373 ulasan**, melampaui target minimal 10.000.\n",
        "  - **Analisis Kritis:** Dataset sebesar ini memberikan fondasi yang sangat kuat untuk melatih model Deep Learning yang kompleks dan *data-hungry*. Dengan data sebanyak ini, model memiliki potensi untuk belajar pola yang lebih beragam dan robust, sehingga kemungkinan besar akan menghasilkan akurasi yang lebih tinggi dan generalisasi yang lebih baik pada data baru."
      ],
      "metadata": {
        "id": "XN-m2az25z18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Pengambilan Sampel Acak (Random Sampling)**\n",
        "Mengambil 10.300 sampel acak dari total data untuk efisiensi."
      ],
      "metadata": {
        "id": "bc5RlwzNBa_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan jumlah sampel yang diinginkan\n",
        "sample_size = 10300\n",
        "\n",
        "# Melakukan random sampling (data yang di-scrape lebih besar dari ukuran sampel)\n",
        "if len(df_reviews) > sample_size:\n",
        "    print(f\"\\nMelakukan random sampling untuk mengambil {sample_size} ulasan...\")\n",
        "    # Menggunakan random_state=42 agar hasil sampling konsisten\n",
        "    df_sampled = df_reviews.sample(n=sample_size, random_state=42)\n",
        "else:\n",
        "    print(\"\\nJumlah data kurang dari ukuran sampel, semua data akan digunakan.\")\n",
        "    df_sampled = df_reviews\n",
        "\n",
        "print(f\"Ukuran dataset setelah sampling: {len(df_sampled)} ulasan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDvFnB_WBfbA",
        "outputId": "aac62034-8afd-43d5-b42a-f230f07e1c73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melakukan random sampling untuk mengambil 10300 ulasan...\n",
            "Ukuran dataset setelah sampling: 10300 ulasan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Metode yang digunakan**\n",
        "-   **Pengambilan Sampel Acak (Random Sampling):** Teknik statistik ini diimplementasikan menggunakan metode `pandas.DataFrame.sample()`. Metode ini memilih baris-baris dari DataFrame secara acak tanpa penggantian.\n",
        "-   **Logika Kondisional (`if-else`):** Kode ini dibungkus dalam sebuah struktur `if-else` untuk memeriksa apakah jumlah total ulasan yang di-scrape (`len(df_reviews)`) melebihi ukuran sampel yang diinginkan (`sample_size`).\n",
        "-   **Parameterisasi:** Ukuran sampel (`10.300`) dan status acak (`random_state=42`) ditetapkan sebagai parameter eksplisit untuk kontrol dan reproduktifitas.\n",
        "\n",
        "#### **Alasan penggunaan**\n",
        "-   **Keseimbangan antara Kuantitas dan Efisiensi:** Memproses data yang besar itu akan sangat memakan waktu dan sumber daya komputasi (terutama pada platform Google Colab). Dengan mengambil **10.300 sampel**, kita mencapai dua tujuan strategis:\n",
        "    1.  **Memenuhi Kriteria:** Jumlah 10.300 sampel dengan nyaman melampaui syarat minimal 10.000 data untuk mendapatkan nilai tinggi.\n",
        "    2.  **Meningkatkan Efisiensi:** Ukuran dataset menjadi lebih dapat dikelola, memungkinkan proses *preprocessing*, pelatihan model, dan eksperimen berjalan jauh lebih cepat.\n",
        "\n",
        "-   **Menghindari Bias Sampel (Sampling Bias):** Alasan utama memilih `sample()` adalah untuk **menjamin representasi data yang adil**. Karena data diurutkan berdasarkan yang terbaru (`Sort.NEWEST`), mengambil data teratas akan menciptakan bias waktu (hanya menganalisis ulasan baru). Random sampling memastikan bahwa sampel yang diambil adalah \"miniatur\" yang representatif dari keseluruhan populasi ulasan, mencakup baik ulasan baru maupun yang sedikit lebih lama.\n",
        "\n",
        "-   **Menjamin Reproduktifitas Ilmiah:** Penggunaan `random_state=42` adalah pilar dari penelitian yang dapat direproduksi. Parameter ini memastikan bahwa setiap kali kode ini dijalankan, sampel acak yang \"terpilih\" akan **selalu sama**. Tanpa ini, setiap eksekusi akan menghasilkan dataset yang berbeda, yang akan menyebabkan hasil pelatihan model juga berbeda-beda. Hal ini akan menyulitkan proses debugging, evaluasi, dan perbandingan antar model secara adil.\n",
        "\n",
        "#### **Insight dan Hasil yang didapat**\n",
        "-   **Konfirmasi Eksekusi yang Sukses:** Output teks `Melakukan random sampling...` dan `Ukuran dataset setelah sampling: 10.300 ulasan.` secara jelas mengonfirmasi bahwa logika `if` berjalan sesuai rencana. Kode berhasil mengidentifikasi bahwa jumlah data target (10.300) dan mengeksekusi proses sampling dengan benar.\n",
        "\n",
        "-   **Penciptaan Aset Data Utama:** Hasil paling fundamental adalah terbentuknya DataFrame baru, yaitu `df_sampled`. DataFrame inilah yang menjadi **aset data utama** untuk keseluruhan sisa proyek. Semua tahapan selanjutnya‚Äîmulai dari pembersihan, pelabelan, preprocessing, hingga pemodelan‚Äîakan beroperasi pada dataset yang sudah terdefinisi dengan baik, berukuran 10.300 sampel ini."
      ],
      "metadata": {
        "id": "HFVu8bghBwj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Pemilihan Kolom dan Penyimpanan ke CSV**"
      ],
      "metadata": {
        "id": "V1fmfWqtCDko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 4: Memilih Kolom yang Relevan ---\n",
        "# Menggunakan kolom-kolom yang penting untuk analisis sentimen.\n",
        "relevant_columns = ['userName', 'content', 'score', 'at']\n",
        "# Menggunakan df_sampled, bukan df_reviews lagi\n",
        "df_final = df_sampled[relevant_columns]\n",
        "\n",
        "# 'userName': Nama pengguna\n",
        "# 'content': Isi ulasan/review\n",
        "# 'score': Rating yang diberikan (1-5)\n",
        "# 'at': Tanggal ulasan dibuat"
      ],
      "metadata": {
        "id": "94BMLYON50J2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Metode yang digunakan:** *Slicing* (pemotongan) DataFrame.\n",
        "- **Alasan penggunaan:** Efisiensi dan Relevansi. Tidak semua kolom yang disediakan oleh scraper (seperti `reviewId`, `userImage`, `replyContent`, dll.) diperlukan untuk analisis sentimen. Dengan memilih hanya kolom-kolom esensial (`userName`, `content`, `score`, `at`), kita:\n",
        "    1.  Mengurangi penggunaan memori.\n",
        "    2.  Menyederhanakan dataset, membuatnya lebih mudah untuk ditangani.\n",
        "    3.  Fokus pada fitur-fitur yang akan digunakan langsung: `content` untuk teks, `score` untuk pelabelan, `userName` dan `at` untuk analisis kontekstual jika diperlukan.\n",
        "- **Insight dan Hasil yang didapat:** Proses ini mengubah DataFrame mentah yang \"gemuk\" menjadi DataFrame yang \"ramping\" dan siap pakai, tanpa kehilangan informasi yang krusial untuk proyek."
      ],
      "metadata": {
        "id": "w6m0km7u6DxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Langkah 5: Simpan DataFrame ke File CSV ---\n",
        "# Menyimpan data bersih ke dalam file CSV.\n",
        "output_filename = 'dataset_mamikos.csv' # meberikan nama output file 'dataset_mamikos.csv'\n",
        "df_final.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nData ulasan (sampel {len(df_final)} baris) telah berhasil disimpan ke file: {output_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onkWGSWf6EDy",
        "outputId": "352f53e4-9202-4b90-df51-ad8c34ba75fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data ulasan (sampel 10300 baris) telah berhasil disimpan ke file: dataset_mamikos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output:**\n",
        "`Data ulasan (sampel 10.300 baris) telah berhasil disimpan ke file: dataset_mamikos.csv`\n",
        "\n",
        "- **Metode yang digunakan:** Menyimpan DataFrame ke file menggunakan metode `.to_csv()`.\n",
        "- **Alasan penggunaan:** **Persistensi Data.** Tahap ini sangat penting untuk memisahkan alur kerja. Dengan menyimpan hasil scraping ke file `.csv`, kita tidak perlu menjalankan ulang proses scraping yang memakan waktu setiap kali kita ingin mengerjakan notebook pemodelan. Notebook pemodelan nantinya hanya perlu memuat file `dataset_mamikos.csv` ini, membuat proses pengembangan lebih cepat dan modular. Parameter `index=False` digunakan untuk mencegah Pandas menulis kolom indeks yang tidak perlu ke dalam file.\n",
        "- **Insight dan Hasil yang didapat:** Kengonfirmasi bahwa aset data utama proyek telah berhasil dibuat dan disimpan. Proyek ini sekarang memiliki sumber data yang solid dan dapat digunakan kembali."
      ],
      "metadata": {
        "id": "tTcrjGT-6XD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan 20 baris pertama dari data yang disimpan\n",
        "print(\"\\nContoh 20 data pertama dari file yang disimpan:\")\n",
        "print(df_final.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLPQNO1k6Xq8",
        "outputId": "ac884a9e-d9a2-44d5-f52b-f62543f1a312"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contoh 20 data pertama dari file yang disimpan:\n",
            "              userName                                            content  \\\n",
            "1350   Pengguna Google                                          la respon   \n",
            "1082   Pengguna Google  Bagi siapa saja yang membutuhkan sewa kos kosa...   \n",
            "673    Pengguna Google                                            bagus..   \n",
            "3043   Pengguna Google                  Aplikasi yang sangat membantuüëçüëçüëçüëç   \n",
            "10296  Pengguna Google                                           Gandosss   \n",
            "2275   Pengguna Google  Aplikasi yang sangat bagus sangat membantu bag...   \n",
            "5769   Pengguna Google                                              bagus   \n",
            "5958   Pengguna Google                                  sangat bermanfaat   \n",
            "542    Pengguna Google  Baru Pasang kost sekitar 2mingguan udah njepra...   \n",
            "6018   Pengguna Google  Awalnya ragu untuk cari kost ditempat yg gak a...   \n",
            "7787   Pengguna Google  Memudahkan pencarian, sebaiknya dipersering up...   \n",
            "35     Pengguna Google  sangat membantu sekali buat pemilik kost.tapi ...   \n",
            "469    Pengguna Google  Aneh sekali saya tidak bisa mencari kosan saya...   \n",
            "1768   Pengguna Google  Aplikasi ini sangat membantu utk mencari kos k...   \n",
            "8207   Pengguna Google                                          Coba dulu   \n",
            "483    Pengguna Google  Min, kalo bisa review kost disamain kaya revie...   \n",
            "2947   Pengguna Google           Chatnya ko ga dibales si sama kost annya   \n",
            "883    Pengguna Google                                              Bagus   \n",
            "590    Pengguna Google  Tolonglah Fitur Limit Chat nya di hapus saja a...   \n",
            "9981   Pengguna Google  Gak lengkap mau cari daerah gedangan sidoarjo....   \n",
            "\n",
            "       score                  at  \n",
            "1350       2 2022-10-01 10:24:14  \n",
            "1082       5 2023-02-03 21:54:33  \n",
            "673        5 2023-07-15 10:26:55  \n",
            "3043       5 2021-02-28 10:26:00  \n",
            "10296      5 2016-04-09 01:46:30  \n",
            "2275       5 2022-06-04 23:49:26  \n",
            "5769       5 2019-07-08 01:57:14  \n",
            "5958       5 2019-05-02 22:12:56  \n",
            "542        2 2023-10-30 14:12:03  \n",
            "6018       5 2019-04-21 03:26:38  \n",
            "7787       4 2018-07-06 01:51:53  \n",
            "35         5 2025-04-20 11:40:50  \n",
            "469        1 2023-12-31 00:50:37  \n",
            "1768       5 2022-06-20 05:14:16  \n",
            "8207       3 2018-04-06 09:44:22  \n",
            "483        5 2023-12-18 01:45:51  \n",
            "2947       3 2021-05-18 15:14:24  \n",
            "883        5 2023-06-04 18:35:02  \n",
            "590        3 2023-09-18 05:49:05  \n",
            "9981       1 2016-09-05 06:44:03  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Metode yang digunakan:** Inspeksi data menggunakan metode `.head()`.\n",
        "- **Alasan penggunaan:** Sebagai langkah verifikasi akhir atau *sanity check*. Ini memungkinkan kita untuk melihat secara langsung sampel dari data yang telah disimpan, memastikan bahwa struktur kolom, tipe data, dan isinya sesuai dengan yang diharapkan.\n",
        "- **Insight dan Hasil yang didapat:**\n",
        "  - Menunjukkan data yang bersih dan terstruktur dengan benar dalam 4 kolom yang telah dipilih.\n",
        "  - Terdapat juga variasi skor yang akan menjadi dasar pelabelan sentimen (Negatif, Netral, Positif).\n",
        "  - Format tanggal pada kolom `at` terlihat konsisten. Secara keseluruhan, data ini siap untuk tahap selanjutnya yaitu preprocessing dan pemodelan."
      ],
      "metadata": {
        "id": "cpt5p9XT6Y5_"
      }
    }
  ]
}